{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "212a530d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5efab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text data (replace with actual dataset)\n",
    "texts = [\n",
    "    \"Once upon a time, there was a brave knight.\",\n",
    "    \"In a galaxy far, far away, there was a great adventure.\"\n",
    "]\n",
    "\n",
    "# Save the texts in a file (optional, for demonstration purposes)\n",
    "with open('data.txt', 'w') as f:\n",
    "    for text in texts:\n",
    "        f.write(text + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8b22b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Remove noise and special characters\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess the texts\n",
    "preprocessed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "# Print the preprocessed texts\n",
    "print(preprocessed_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc9836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-2 tokenizer and model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Encode the preprocessed texts\n",
    "inputs = tokenizer(preprocessed_texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "train_inputs, val_inputs = train_test_split(inputs.input_ids, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cf59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_inputs,\n",
    "    eval_dataset=val_inputs\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df204bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate text\n",
    "def generate_text(prompt, max_length=50):\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "    outputs = model.generate(inputs.input_ids, max_length=max_length, num_return_sequences=1)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Example usage\n",
    "prompt = \"In a land far away\"\n",
    "generated_text = generate_text(prompt)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265abf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example evaluation (using BLEU score) with trials\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "# Define a reference text (replace with actual reference text)\n",
    "reference = [\"In a land far away, there was a beautiful princess.\"]\n",
    "\n",
    "# Generate a text based on a prompt\n",
    "generated = generate_text(\"In a land far away\")\n",
    "\n",
    "# Trial: Tokenize the reference and generated texts\n",
    "reference_tokens = [nltk.word_tokenize(ref) for ref in reference]\n",
    "generated_tokens = nltk.word_tokenize(generated)\n",
    "print(\"Reference tokens:\", reference_tokens)\n",
    "print(\"Generated tokens:\", generated_tokens)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu(reference_tokens, generated_tokens)\n",
    "print(f\"BLEU score: {bleu_score}\")\n",
    "\n",
    "# Trial: Adjust prompt and evaluate again\n",
    "new_prompt = \"In a distant kingdom\"\n",
    "new_generated = generate_text(new_prompt)\n",
    "new_generated_tokens = nltk.word_tokenize(new_generated)\n",
    "new_bleu_score = sentence_bleu(reference_tokens, new_generated_tokens)\n",
    "print(f\"New BLEU score with adjusted prompt: {new_bleu_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
